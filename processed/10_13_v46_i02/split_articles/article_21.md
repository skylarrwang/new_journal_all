Publication date: 10/13
Volume 46, Issue 2

**Title: The Digital Humanities at Yale**
**Author: Unlisted**
**Page number(s): 22-24**

EXTRACT ARTICLE CONTENT:
22
the new journal
of Sterling, thick volumes of Old Norse, 
Swedish, and Icelandic literature sit next 
to a few well-worn books on program­
ming. One shelf is dedicated to a few relics 
of technologies past: a motherboard from 
a 1980s NEXT computer sits alongside a 
Nune, a tablet-style educational device 
from the early nineties. 


Leonard’s path to the digital humani­
ties began with a relatively traditional 
humanities education: an undergraduate 
degree in art history and a graduate degree 
in literature. Like most literature students, 
he was trained to read a novel closely and 
meticulously, and to 
dissect 
paragraphs 
around a seminar ta­
ble. It was only during 
his postdoctoral work 
at UCLA in Nordic lit­
erature that Leonard 
became interested in 
quantitative approach­
es to literary questions. Today, he focuses 
on computer analyses of large collections 
of digital texts. As an example of this tech­
nique, he showed me an analysis he con­
ducted on 120 years worth of Vogue maga­
zines. The project tracked changes in the 
publication’s attention to particular topics 
from decade to decade. In the early twen­
tieth century, the editors were more inter­
ested in social interactions; more recently, 
the focus has shifted to beauty products 
and fashion.


As digital librarian, Leonard will help 
define a young and diffuse field. Since com­
ing to Yale, he has begun holding open of­
fice hours every Thursday with the Digital 
Humanities Working Group, fielding ques­
tions from students and faculty, and get­
ting a sense of what the digital humanities 
will look like at Yale. “The definition of dig­
ital humanities is probably a little different 
on every campus,” Leonard explained. In 
addition to computational research meth­
ods and digitization, the digital humani­
ties can include fields such as instructional 
technology and new media studies. How 
these areas will relate to one another and 
which ones Yale will focus on are questions 
that Leonard and other Yale researchers 
are working to answer.


There’s also another, perhaps even more 
pressing question to consider: how will the 
digital humanities define its work in re­
lation to the disciplines from which it so 
often borrows tools, such as the social sci­
ences? The technical challenges of repur­
posing the objective, mathematical tools of 
the social sciences or of representing the 
full complexity of a manuscript in a digital 
form, mask a deeper tension in reconciling 
the work of very different 
disciplines: one that focus­
es on data-driven, empiri­
cal answers, and the other 
which is more comfortable 
with ambiguity and open-
ended questions. Leonard 
asks, “how do we make use 
of techniques that might 
emerge from outside our disciplines, with­
out becoming unduly beholden to them?”


One of the earliest projects in the digi­
tal humanities was finding ways to turn 
physical collections of “humanities data”—
which can range from scholarly works to 
novels, photographic images to historical 
records—into a form that can be analyzed 
by a computer. That project of digitization 
remains at the center of the discipline.


The work of women’s, gender, and sex­
uality studies professor Laura Wexler, a 
photographic historian, falls into this cat­
egory. She oversees a collaborative digital 
humanities project spearheaded by gradu­
ate students Lauren Tilton and Taylor Ar­
nold, who come, respectively, from the 
fields of American Studies and statistics. 
The team is mapping and analyzing over 
160,000 photos taken by photographers 
hired by the federal Farm Security Admin­
istration’s Office of War and Information 
from 1935 to 1945, creating an online da­
tabase that is searchable and accessible to 
a range of audiences from middle schoolers 
“A book communicates 
meaning to us, but it 
doesn’t communicate 
meaning to a machine.”


--- Page 23 ---

september 2013
23
to schoolteachers to academics.


A version of Photogrammer, the tool 
they’ve created, is now available online in 
beta. You can easily follow a particular pho­
tographer’s walk around Chicago, search 
for photos from your home county, or use 
the caption search to find every image con­
taining a lumberjack. A few decades ago, 
the only way to look at these photos would 
be to rifle though hundreds of file cabinets 
in a dank basement in Washington.


Wexler, Tilton, and Arnold are still de­
termining what kinds of questions they 
might answer with their newly collected 
data. Beyond correlating various attributes 
of the photos and the geographical loca­
tion where they were taken, they’re also 
interested in harnessing the potential of 
crowdsourcing. “It’s designed to be a public 
platform,” Wexler explained. Users could 
participate by tagging photos or uploading 
current images of the same locations to see 
what’s changed.


“We were able to take this big messy 
data set and put it into a form that’s nim­
ble,” said Wexler. Humanities data tends to 
be disorganized, posing interesting techni­
cal challenges for programmers. The very 
idea of “data” in the humanities has been 
challenged by some scholars, such as Jo­
anna Drucker, a professor of information 
studies at UCLA, who argues that rather 
than thinking of data as a direct represen­
tation of reality—in the sense of its Latin 
root, which means “what is given”—we 
should think of it as something that is col­
lected and constructed. Digital data offers 
only a partial representation of an object; 
the object has to be broken down into a set 
of encoded attributes before it can appear 
on your screen. Deciding how to divide an 
object like a painting into a few lines of 
code is the biggest challenge in any digiti­
zation project.


“A book communicates meaning to us, 
but it doesn’t communicate meaning to a 
machine,” said Carol Chiodo, a Dante schol­
ar and member of the Digital Humanities 
Working Group. “Anyone who’s tried to 
extract text from a PDF knows that.” She 
pointed to the Text Encoding Initiative 
(TEI) as a set of guidelines for how to for­
mat texts so that computers can under­
stand them. These guidelines determine 
how to mark important features such as 
paragraph, section, and chapter breaks.  
If you’ve ever been forced by a website 
to prove you’re a human by transcribing 
a nearly unreadable word, you may have 
contributed to cleaning up some messy hu­
manities data yourself. These “CAPTCHA” 
(“Completely Automated Public Turing test 
to tell Computers and Humans Apart”) chal­
lenges are used by websites to ensure that 
someone filling data into a form isn’t actu­
ally an automated program attempting to 
hack the system. A decoding system called 
reCAPTCHA manipulates this tool for re­
search by taking images from old manu­
scripts in the process of being digitized and 
using them as challenges. Algorithms iden­
tify which words in a manuscript are most 
likely to have been wrongly transcribed, 
and these are outsourced to an army of un­
witting Internet users. reCAPTCHA’s first 
project was cleaning up digitizations of the 
New York Times, but it’s now moving on to 
work on the millions of books scanned by 
Google. 


Technical challenges like these are 
part of what draws computer scientists to 
get involved with the digital humanities. 
“Humanists aren’t inhibited by knowing 
what’s difficult to accomplish with com­
putational techniques, so that can lead us 
to interesting new challenges,” said Holly 
Rushmeier, chair of Yale’s computer sci­
ence department. Rushmeier’s work often 
involves visual data mining: transforming 
objects or images into digital data that can 
be manipulated and analyzed. Before com­
ing to Yale, she worked on several cultural 
heritage projects at IBM. One involved 
creating a digital model of Michelangelo’s 
Pietà. The statue was partially destroyed 
by Michelangelo himself, and another 
sculptor attempted to repair it. An art his­
torian who was trying to understand what 


--- Page 24 ---

24
drove Michelangelo to damage his own 
work wanted to see how the statue looked 
with the repaired pieces removed. The 
techniques developed in the course of the 
project weren’t just of future use to schol­
ars, but also to the development of com­
mercial 3D imaging products.  “With this 
type of work, you have both the immediate 
benefit for the scholar, and all these spin-
off benefits,” said Rushmeier. 


But what about the “great unread”? Pe­
ter Leonard is helping some Swedish schol­
ars use a program that can identify topics 
in a huge collection of novels. He showed 
me a page of results. Each topic is displayed 
as a cluster of words, their relative sizes 
depending on their importance in the text, 
with related passages on the side. 


The topics aren’t suggested by the re­
searcher, but are drawn out of the text by 
the program itself. “The wonderful and 
terrible thing about it is that it only shows 
you what it thinks is there,” Leonard said. 
There are limitations, of course—a com­
puter can’t read 1984 and come out with a 
topic called “fascism” if it’s never directly 
mentioned—but topic modeling can expose 
unexpected connections. 


Techniques like topic modeling can 
have larger implications for academic 
fields, and could potentially alter the can­
on itself. Leonard gave me the example 
of research done on nineteenth-century 
Swedish novels. When studying these nov­
els, scholars had usually focused on the 
works of Ibsen and Strindberg, identifying 
the authors as primarily responsible in the 
drive to replace Romanticism with real­
ism during that period, writing about the 
economic rights of women and life in bour­
geois households. 


In the seventies, though, painstaking 
archival research showed that there was 
also a large cohort of female writers who 
contributed to this movement, examining 
topics that had previously been ascribed 
solely to men. Those researchers were us­
ing traditional techniques—reading as 
many books in the archive as possible. 
Forty years later, digital humanities schol­
ars wanted to see if they could find similar 
results using topic modeling. They found 
that the same topics that turned up in Ib­
sen and Strindberg were also in the works 
of female writers.


“In that case, we had a cheat sheet to 
check our results against,” said Leonard. 
But it was proof that the technique could 
identify previously overlooked pockets of 
important scholarly work.


While nearly every faculty member I 
spoke to was excited about the potential of 
the digital humanities to analyze large vol­
umes of humanities data, they all acknowl­
edged certain limitations. The first prob­
lem is assembling a truly comprehensive 
collection of humanities data in the first 
place, when not all of it is accessible.


“There’s a selection process at every 
stage,” Leonard explained. “First, not every 
writer gets their book published. Then, not 
every book gets purchased. Over the next 
hundred years, the library makes decisions 
about whether we should keep these books. 
“Now the question is: which books do we 
want to send to Google?” Because informa­
tion is lost at each step, scholars need to 
qualify their conclusions to acknowledge 
the way these missing pieces could bias 
their results.


Of course, there are humanities ques­
tions that this sort of approach simply can’t 
answer. For more contextualized and nu­
anced readings of particular texts, we need 
humans, not machines. “No one’s trying to 
say, Oh, it’s time to become a big data scien­
tist and forget humanities training,” Leon­
ard said. “But we can keep that incredible 
value as we use new techniques to engage 
with works that might have fallen outside 
the canon.”


Franco Moretti, a digital humanities 
pioneer and founder of the Stanford Lit­
erature Lab, snuck a jab at Yale into his 
well-known, now decade-old essay, “The